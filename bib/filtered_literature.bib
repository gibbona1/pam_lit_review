@incollection{ref1,
  title    = {Detection and classification methods for animal sounds},
  author   = {Oswald J.N.; Erbe C.; Gannon W.L.; Madhusudhana S.; Thomas J.A.},
  year     = {2022},
  journal  = {Exploring Animal Behavior Through Sound: Volume 1: Methods},
  abstract = {Classification of the acoustic repertoires of animals into sound types is a useful tool for taxonomic studies, behavioral studies, and for documenting the occurrence of animals. Classification of acoustic repertoires enables the identification of species, age, gender, and individual identity, correlations between sound types and behavior, the identification of changes in vocal behavior over time or in response to anthropogenic noise, comparisons between the repertoires of populations living in different geographic regions and environments, and the development of software tools for automated signal processing. Techniques for classification have evolved over time as technical capabilities have expanded. Initially, researchers applied qualitative methods, such as listening and visually discerning sounds in spectrograms. Advances in computer technology and the development of software for the automatic detection and classification of sounds have allowed bioacousticians to quickly find sounds in recordings, thus significantly reducing analysis time and enabling the analysis of larger datasets. In this chapter, we present software algorithms for automated signal detection (based on energy, Teager-Kaiser energy, spectral entropy, matched filtering, and spectrogram cross-correlation) as well as for signal classification (e.g., parametric clustering, principal component analysis, discriminant function analysis, classification trees, artificial neural networks, random forests, Gaussian mixture models, support vector machines, dynamic time-warping, and hidden Markov models). Methods for evaluating the performance of automated tools are presented (i.e., receiver operating characteristics and precision-recall) and challenges with classifying animal sounds are discussed. © The Author(s) 2022. All rights reseverd.},
  keywords = {},
  doi      = {10.1007/978-3-030-97540-1_8},
  url      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144309331&doi=10.1007%2f978-3-030-97540-1_8&partnerID=40&md5=4003b35c2685e54aa2f7fa38b0caaf11}
}


@article{ref2,
  title    = {Improve automatic detection of animal call sequences with temporal context},
  author   = {Madhusudhana S.; Shiu Y.; Klinck H.; Fleishman E.; Liu X.; Nosal E.-M.; Helble T.; Cholewiak D.; Gillespie D.; Širovic A.; Roch M.A.},
  year     = {2021},
  journal  = {Journal of the Royal Society Interface},
  abstract = {Many animals rely on long-form communication, in the form of songs, for vital functions such as mate attraction and territorial defence. We explored the prospect of improving automatic recognition performance by using the temporal context inherent in song. The ability to accurately detect sequences of calls has implications for conservation and biological studies. We show that the performance of a convolutional neural network (CNN), designed to detect song notes (calls) in short-duration audio segments, can be improved by combining it with a recurrent network designed to process sequences of learned representations from the CNN on a longer time scale. The combined system of independently trained CNN and long short-term memory (LSTM) network models exploits the temporal patterns between song notes. We demonstrate the technique using recordings of fin whale (Balaenoptera physalus) songs, which comprise patterned sequences of characteristic notes. We evaluated several variants of the CNN+ LSTM network. Relative to the baseline CNN model, the CNN+ LSTM models reduced performance variance, offering a 9-17% increase in area under the precision-recall curve and a 9-18% increase in peak F1-scores. These results show that the inclusion of temporal information may offer a valuable pathway for improving the automatic recognition and transcription of wildlife recordings. © 2021 The Author(s).},
  keywords = {Animals; Neural Networks, Computer; Time Factors; Animals; Convolutional neural networks; Automatic Detection; Automatic recognition; Biological studies; Combined system; Recurrent networks; Short durations; Temporal information; Temporal pattern; article; convolutional neural network; fin whale; genetic transcription; long short term memory network; nonhuman; recall; wildlife; animal; time factor; Long short-term memory},
  doi      = {10.1098/rsif.2021.0297},
  url      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111982081&doi=10.1098%2frsif.2021.0297&partnerID=40&md5=4c352c2a97bbf466ba2bc605fcf6ec8d}
}


@article{ref3,
  title    = {Automatic recognition and classification of cattle chewing activity by an acoustic monitoring method with a single-axis acceleration sensor},
  author   = {Tani Y.; Yokota Y.; Yayota M.; Ohtani S.},
  year     = {2013},
  journal  = {Computers and Electronics in Agriculture},
  abstract = {Monitoring the eating habits and rumination of cattle is effective for evaluating forage values and making animal management decisions for stalls and grazing pastures. Acoustic monitoring is a feasible method to monitor these activities, but it requires automatic distinction and quantification of activities to gain broader application. This automatic distinction and quantification may be possible using a pattern matching method, which distinguishes jaw movements by extracting characteristic patterns from eating and ruminating, and then matches similar characteristic patterns in unanalyzed activities. The objectives of this study were to define an acoustic monitoring system with a single-axis acceleration sensor, to determine an effective sensor attachment site (i.e., the horn, forehead, or nasal bridge), and to assess the automatic classification of ingestive and ruminative chewing behaviors using a pattern matching method. Four beef cows fed Italian ryegrass silage were each recorded eating and ruminating for more than 60 and 20. min, respectively. The oscillatory waveforms generated while eating and ruminating were clearly recorded by the single-axis acceleration sensor, regardless of sensor attachment site. The pattern matching method correctly distinguished ingestive chewing with an accuracy of over 0.9, regardless of the sensor site (estimated number of chews by automatic detection/true number of chews by manual detection). Placement of the sensor on the horn of the animal resulted in the most matched measurement (0.99). In contrast, the method overestimated ruminating chewing time (approximately 1.50) because noises that occurred during idling were misclassified as ruminating chewing. The provision of an additional chewing criterion for automatic detection, i.e., chewing is performed consecutively (context-based cues), improved the classification accuracy of ruminating to a range of 1.02-1.08. In conclusion, automatic detection using a pattern matching method successfully classified ingestive chewing and ruminating chewing in cattle, and a single-axis acceleration sensor was useful for acoustic monitoring at all sensor attachment sites. © 2013 Elsevier B.V.},
  keywords = {Acoustic measuring instruments; Bioacoustics; Mammals; Monitoring; Pattern matching; Acceleration sensors; Acoustic monitoring; Automatic classification; Automatic Detection; Automatic recognition; Classification accuracy; Context-based; Eating habits; Ingestive behavior; Italian ryegrass; Jaw movements; Management decisions; Ruminants; Single-axis; Wave forms; accuracy assessment; agricultural technology; automation; cattle; decision making; detection method; forage; horn; ingestion rate; monitoring system; movement; noise; pasture; pattern recognition; sensor; silage; Sensors},
  doi      = {10.1016/j.compag.2013.01.001},
  url      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873555109&doi=10.1016%2fj.compag.2013.01.001&partnerID=40&md5=2dd2cef24551eaa9b5abaef5c519951c}
}


@inproceedings{ref4,
  title    = {Automatic detection of cow/calf vocalizations in free-stall barn},
  author   = {Ntalampiras S.; Pezzuolo A.; Mattiello S.; Battini M.; Brscic M.},
  year     = {2020},
  journal  = {2020 43rd International Conference on Telecommunications and Signal Processing, TSP 2020},
  abstract = {Precision livestock farming dictates the use of advanced technologies to understand, analyze, assess and finally optimize a farm's production collectively as well as the contribution of each single animal. This Work is part of a research project wishing to steer the dairy farms' producers to more ethical rearing systems. To study cow's welfare, we focus on reciprocal vocalizations including mother-offspring contact calls. We show the set-up of a suitable audio capturing system composed of automated recording units and propose an algorithm to automatically detect cow vocalizations in an indoor farm setting. More specifically, the algorithm has a two-level structure: a) first, the Hilbert follower is applied to segment the raw audio signals, and b) second the detected blocks of acoustic activity are refined via a classification scheme based on hidden Markov models. After thorough evaluation, we demonstrate excellent detection results in terms of false positives, false negatives and confusion matrix. © 2020 IEEE.},
  keywords = {Agriculture; Audio acoustics; Hidden Markov models; Acoustic activity; Advanced technology; Automatic Detection; Classification scheme; Confusion matrices; False negatives; Precision livestock farming; Two-level structures; Signal processing},
  doi      = {10.1109/TSP49548.2020.9163522},
  url      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090556926&doi=10.1109%2fTSP49548.2020.9163522&partnerID=40&md5=4b45a3df7d55118a6f4afc8b496aed5d}
}


@article{ref5,
  title    = {Automatic recognition of fin and blue whale calls for real-time monitoring in the St. Lawrence},
  author   = {Mouy X.; Bahoura M.; Simard Y.},
  year     = {2009},
  journal  = {Journal of the Acoustical Society of America},
  abstract = {Monitoring blue and fin whales summering in the St. Lawrence Estuary with passive acoustics requires call recognition algorithms that can cope with the heavy shipping noise of the St. Lawrence Seaway and with multipath propagation characteristics that generate overlapping copies of the calls. In this paper, the performance of three time-frequency methods aiming at such automatic detection and classification is tested on more than 2000 calls and compared at several levels of signal-to-noise ratio using typical recordings collected in this area. For all methods, image processing techniques are used to reduce the noise in the spectrogram. The first approach consists in matching the spectrogram with binary time-frequency templates of the calls (coincidence of spectrograms). The second approach is based on the extraction of the frequency contours of the calls and their classification using dynamic time warping (DTW) and the vector quantization (VQ) algorithms. The coincidence of spectrograms was the fastest method and performed better for blue whale A and B calls. VQ detected more 20 Hz fin whale calls but with a higher false alarm rate. DTW and VQ outperformed for the more variable blue whale D calls. © 2009 Acoustical Society of America.},
  keywords = {Acoustics; Algorithms; Animals; Atlantic Ocean; Automation; Balaenoptera; Databases as Topic; Fin Whale; Quebec; Signal Processing, Computer-Assisted; Sound Spectrography; Time Factors; Vocalization, Animal; Fins (heat exchange); Image processing; Signal to noise ratio; Spectrographs; Automatic Detection; Automatic recognition; Blue whale; Dynamic time warping; False alarm rate; Image processing technique; Lawrence estuaries; Passive acoustics; Real time monitoring; Recognition algorithm; Spectrograms; Time-frequency methods; Time-frequency template; Whale calls; acoustics; algorithm; article; controlled study; dynamics; fin whale; frequency analysis; image processing; intermethod comparison; monitoring; noise reduction; nonhuman; performance; priority journal; quantitative analysis; recording; signal noise ratio; sound detection; time; whale; Vector quantization},
  doi      = {10.1121/1.3257588},
  url      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-72549093668&doi=10.1121%2f1.3257588&partnerID=40&md5=32c51ed35e00cc1beab6b801aaf9b0bd}
}


@article{ref6,
  title    = {Dynamics of communal vocalizations in a social songbird, the zebra finch (Taeniopygia guttata)},
  author   = {Elie J.E.; Soula H.A.; Mathevon N.; Vignal C.},
  year     = {2011},
  journal  = {Journal of the Acoustical Society of America},
  abstract = {Colonies or communities of animals such as fishes, frogs, seabirds, or marine mammals can be noisy. Although vocal communication between clearly identified sender(s) and receiver(s) has been well studied, the properties of the noisy sound that results from the acoustic network of a colony of gregarious animals have received less attention. The resulting sound could nonetheless convey some information about the emitting group. Using custom-written software for automatic detection of vocalizations occurring over many hours of recordings, this study reports acoustic features of communal vocal activities in a gregarious species, the zebra finch (Taeniopygia guttata). By biasing the sex ratio and using two different housing conditions (individual versus communal housing), six groups of zebra finches were generated, with six different social structures that varied both in terms of sex-composition and proportion of paired individuals. The results showed that the rate of emission and the acoustic dynamic both depended on the social structure. In particular, the vocal activity of a group of zebra finches depended mainly on the number of unpaired birds, i.e., individuals not part of a stably bonded pair. © 2011 Acoustical Society of America.},
  keywords = {Housing; Mammals; Acoustic dynamics; Acoustic features; Acoustic network; Automatic Detection; Marine mammals; Sex ratios; Social structure; Bioacoustics},
  doi      = {10.1121/1.3570959},
  url      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959479153&doi=10.1121%2f1.3570959&partnerID=40&md5=0f8604c716177356a511a10801a51801}
}


@article{ref7,
  title    = {An acoustic detection dataset of birds (Aves) in montane forests using a deep learning approach},
  author   = {Wu S.-H.; Ko J.C.-J.; Lin R.-S.; Tsai W.-L.; Chang H.-W.},
  year     = {2023},
  journal  = {Biodiversity Data Journal},
  abstract = {Background Long-term monitoring is needed to understand the statuses and trends of wildlife communities in montane forests, such as those in Yushan National Park (YSNP), Taiwan. Integrating passive acoustic monitoring (PAM) with an automated sound identifier, a longterm biodiversity monitoring project containing six PAM stations, was launched in YSNP in January 2020 and is currently ongoing. SILIC, an automated wildlife sound identification model, was used to extract sounds and species information from the recordings collected. Animal vocal activity can reflect their breeding status, behaviour, population, movement and distribution, which may be affected by factors, such as habitat loss, climate change and human activity. This massive amount of wildlife vocalisation dataset can provide essential information for the National Park's headquarters on resource management and decision-making. It can also be valuable for those studying the effects of climate change on animal distribution and behaviour at a regional or global scale.New information To our best knowledge, this is the first open-access dataset with species occurrence data extracted from sounds in soundscape recordings by artificial intelligence. We obtained seven bird species for the first release, with more bird species and other taxa, such as mammals and frogs, to be updated annually. Raw recordings containing over 1.7 million one-minute recordings collected between the years 2020 and 2021 were analysed and SILIC identified 6,243,820 vocalisations of seven bird species in 439,275 recordings. The automatic detection had a precision of 0.95 and the recall ranged from 0.48 to 0.80. In terms of the balance between precision and recall, we prioritised increasing precision over recall in order to minimise false positive detections. In this dataset, we summarised the count of vocalisations detected per sound class per recording which resulted in 802,670 occurrence records. Unlike data from traditional human observation methods, the number of observations in the Darwin Core "organismQuantity" column refers to the number of vocalisations detected for a specific bird species and cannot be directly linked to the number of individuals. We expect our dataset will be able to help fill the data gaps of fine-scale avian temporal activity patterns in montane forests and contribute to studies concerning the impacts of climate change on montane forest ecosystems on regional or global scales. © Wu S et al. This is an open access article distributed under the terms of the Creative Commons Attribution License (CC BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
  keywords = {Australia; Darwin; Northern Territory; Taiwan; Yushan National Park; acoustic method; biodiversity; bird; climate change; data set; montane forest; reproductive behavior; species occurrence},
  doi      = {10.3897/BDJ.11.E97811},
  url      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153360818&doi=10.3897%2fBDJ.11.E97811&partnerID=40&md5=ef42ba52b49d6d861a8a45dc147b8cc3}
}


@inproceedings{ref8,
  title    = {Real-time Detection and Classification for Targeted Marine Mammals},
  author   = {Chen Y.; Wang W.; Liang Y.; Zhou D.; Dong C.; Li J.},
  year     = {2021},
  journal  = {2021 OES China Ocean Acoustics, COA 2021},
  abstract = {With the continuous development of offshore engineering, major offshore projects develop rapidly. During the development of offshore engineering, different degrees of noise will be generated, and the man-made noise can have harmful effects on marine mammals. Currently, The researchers usually use Passive Acoustic Monitoring(PAM) method to monitor the marine mammals. However, it is impossible to acquire, monitor and analyze the sound of marine mammals in real time and lack of comprehensive information of marine mammals monitoring, and the data analysis and study of vocalization rules can only be carried out after data collection is completed and equipment is recovered. Therefore, this paper proposes a real-time automatic detection and classification technology to monitor targeted marine mammals efficiently and continuously timely in offshore engineering areas. © 2021 IEEE.},
  keywords = {Acoustic noise; Offshore oil well production; Signal detection; Automatic classification; Automatic Detection; Continuous development; Mammal detection; Marine mammal detection; Marine mammals; Offshore engineering; Offshore project; Real- time; Real-time detection; Mammals},
  doi      = {10.1109/COA50123.2021.9519906},
  url      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115414150&doi=10.1109%2fCOA50123.2021.9519906&partnerID=40&md5=c6667a21cf020634ab7522df24ca25cb}
}


@article{ref9,
  title    = {Automated detection of 50-kHz ultrasonic vocalizations using template matching in XBAT},
  author   = {Barker D.J.; Herrera C.; West M.O.},
  year     = {2014},
  journal  = {Journal of Neuroscience Methods},
  abstract = {Background: Ultrasonic vocalizations (USVs) have been utilized to infer animals' affective states in multiple research paradigms including animal models of drug abuse, depression, fear or anxiety disorders, Parkinson's disease, and in studying neural substrates of reward processing. Currently, the analysis of USV data is performed manually, and thus is time consuming. New method: The goal of the present study was to develop a method for automated USV recognition using a 'template detection' procedure for vocalizations in the 50-kHz range (35-80. kHz). The detector is designed to run within XBAT, a MATLAB graphical user interface and extensible bioacoustics tool developed at Cornell University. Results: Results show that this method is capable of detecting >90% of emitted USVs and that time spent analyzing data by experimenters is greatly reduced. Comparison with existing methods: Currently, no viable and publicly available methods exist for the automated detection of USVs. The present method, in combination with the XBAT environment is ideal for the USV community as it allows others to (1) detect USVs within a user-friendly environment, (2) make improvements to the detector and disseminate and (3) develop new tools for analysis within the MATLAB environment. Conclusions: The present detector provides an open-source, accurate method for the detection of 50-kHz USVs. Ongoing research will extend the current method for use in the 22-kHz frequency range of ultrasonic vocalizations. Moreover, collaborative efforts among USV researchers may enhance the capabilities of the current detector via changes to the templates and the development of new programs for analysis. © 2014.},
  keywords = {Access to Information; Animals; Cocaine; Dopamine Uptake Inhibitors; Male; Pattern Recognition, Automated; Probability; Rats, Long-Evans; Reproducibility of Results; Self Administration; Signal-To-Noise Ratio; Software; Sound Spectrography; Time Factors; Ultrasonics; User-Computer Interface; Vocalization, Animal; cocaine; dopamine uptake inhibitor; acoustics; animal experiment; article; audio recording; bioacoustics; computer interface; Fourier transformation; male; microphone; nonhuman; priority journal; rat; signal detection; signal noise ratio; sound detection; ultrasonic vocalization; ultrasound; access to information; animal; automated pattern recognition; computer interface; computer program; drug self administration; Long Evans rat; probability; procedures; reproducibility; sound detection; time; vocalization},
  doi      = {10.1016/j.jneumeth.2014.08.007},
  url      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906828550&doi=10.1016%2fj.jneumeth.2014.08.007&partnerID=40&md5=5725561606c1f0193dc298974a284dd2}
}


@inproceedings{ref10,
  title    = {An automatic detection algorithm for extracting the representative frequency of cetacean tonal sounds},
  author   = {Lin T.-H.; Chou L.-S.; Akamatsu T.; Chan H.-C.; Chen C.-F.},
  year     = {2013},
  journal  = {Journal of the Acoustical Society of America},
  abstract = {Most studies on tonal sounds extract contour parameters from fundamental frequencies. The presence of harmonics and the frequency distribution of multiple tonal sounds have not been well researched. To investigate the occurrence and frequency modulation of cetacean tonal sounds, the procedure of detecting the instantaneous frequency bandwidth of tonal spectral peaks was integrated within the local-max detector to extract adopted frequencies. The adopted frequencies, considered the representative frequencies of tonal sounds, are used to find the presence of harmonics and overlapping tonal sounds. The utility and detection performance are demonstrated on acoustic recordings of five species from two databases. The recordings of humpback dolphins showed a 75% detection rate with a 5% false detection rate, and recordings from the MobySound archive showed an 85% detection rate with a 5% false detection rate. These detections were achieved in signal-to-noise ratios of -12 to 21 dB. The parameters that measured the distribution of adopted frequency, as well as the prominence of harmonics and overlaps, indicate that the modulation of tonal sounds varied among different species and behaviors. This algorithm can be applied to studies on cetacean communication signals and long-term passive acoustic monitoring. © 2013 Acoustical Society of America.},
  keywords = {Acoustics; Algorithms; Animals; Cetacea; Dolphins; Environmental Monitoring; Marine Biology; Oceans and Seas; Pattern Recognition, Automated; Reproducibility of Results; Signal Processing, Computer-Assisted; Signal-To-Noise Ratio; Sound Spectrography; Swimming; Time Factors; Vocalization, Animal; Harmonic analysis; Modulation; Automatic detection algorithms; Communication signals; Detection performance; Frequency distributions; Fundamental frequencies; Humpback dolphins; Instantaneous frequency; Passive acoustic monitoring; acoustics; algorithm; animal; automated pattern recognition; Cetacea; conference paper; dolphin; environmental monitoring; marine biology; methodology; physiology; psychological aspect; reproducibility; sea; signal noise ratio; signal processing; sound detection; swimming; time; vocalization; Detectors},
  doi      = {10.1121/1.4816572},
  url      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883386376&doi=10.1121%2f1.4816572&partnerID=40&md5=4bd6655bbb17f719e563075c52467c8c}
}


@article{ref11,
  title    = {On automatic bioacoustic detection of pests: The cases of rhynchophorus ferrugineus and sitophilus ory zae},
  author   = {Ilyas P.; Ganchev T.; Kontodimas D.},
  year     = {2009},
  journal  = {Journal of Economic Entomology},
  abstract = {The present work reports research efforts toward development and evaluation of a unified framework for automatic bioacoustic recognition of specific insect pests. Our approach is based on capturing and automatically recognizing the acoustic emission resulting from typical behaviors, e.g., locomotion and feeding, of the target pests. After acquisition the signals are amplified, filtered, parameterized, and classified by advanced machine learning methods on a portable computer. Specifically, we investigate an advanced signal parameterization scheme that relies on variable size signal segmentation. The feature vector computed for each segment of the signal is composed of the dominant harmonic, which carry information about the periodicity of the signal, and the cepstral coefficients, which carry information about the relative distribution of energy among the different spectral sub-bands. This parameterization offers a reliable representation of both the acoustic emissions of the pests of interest and the interferences from the environment. We illustrate the practical significance of our methodology on two specific cases: 1) a devastating pest for palm plantations, namely, Rhynchophorus ferrugineus Olivier and 2) a pest that attacks warehouse stored rice (Oryza sativa L.), the rice weevil, Sitophilus oryzae (L.) (both Coleoptera: Curculionidae, Dryophorinae). These pests are known in many countries around the world and contribute for significant economical loss. The proposed approach led to detection results in real field trials, reaching 99.1% on real-field recordings of R. ferrugineus and 100% for S. oryzae. © 2009 Entomological Society of America.},
  keywords = {Acoustics; Animals; Behavior, Animal; Feeding Behavior; Food Contamination; Weevils; Coleoptera; Curculionidae; Hexapoda; Oryza sativa; Rhynchophorus ferrugineus; Sitophilus; Sitophilus oryzae; acoustics; animal; animal behavior; article; evaluation; feeding behavior; food contamination; physiology; weevil},
  doi      = {10.1603/029.102.0436},
  url      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-69649098362&doi=10.1603%2f029.102.0436&partnerID=40&md5=292677cb04765753d3c3dcd8b60bead6}
}


@inproceedings{ref12,
  title    = {Automatic Detection of bird species from audio field recordings using HMM-based modelling of frequency tracks},
  author   = {Jancovic P.; Kokuer M.},
  year     = {2017},
  journal  = {25th European Signal Processing Conference, EUSIPCO 2017},
  abstract = {This paper presents an automatic system for detection of bird species in field recordings. A sinusoidal detection algorithm is employed to segment the acoustic scene into isolated spectro-temporal segments. Each segment is represented as a temporal sequence of frequencies of the detected sinusoid, referred to as frequency track. Each bird species is represented by a set of hidden Markov models (HMMs), each HMM modelling an individual type of bird vocalisation element. These HMMs are obtained in an unsupervised manner. The detection is based on a likelihood ratio of the test utterance against the target bird species and non-target background model. We explore on selection of cohort for modelling the background model, z-norm and t-norm score normalisation techniques and score compensation to deal with outlier data. Experiments are performed using over 40 hours of audio field recordings from 48 bird species plus an additional 16 hours of field recordings as impostor trials. Evaluations are performed using detection error trade-off plots. The equal error rate of 5% is achieved when impostor trials are non-target bird species vocalisations and 1.2% when using field recordings which do not contain bird vocalisations. © EURASIP 2017.},
  keywords = {Economic and social effects; Hidden Markov models; Markov processes; Signal processing; Statistics; Trellis codes; Bird species; Cohort; Element; Field recording; Frequency track; Normalisation; Outlier; Unsupervised training; Vocalisation; Birds},
  doi      = {10.23919/EUSIPCO.2017.8081515},
  url      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041468008&doi=10.23919%2fEUSIPCO.2017.8081515&partnerID=40&md5=d56b84cbcad16b0c155cb1688d64f014}
}


@inproceedings{ref13,
  title    = {Efficient Bird Sound Detection on the Bela Embedded System},
  author   = {Solomes A.-M.; Stowell D.},
  year     = {2020},
  journal  = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
  abstract = {Monitoring wildlife is an important aspect of conservation initiatives. Deep learning detectors can help with this, although it is not yet clear whether they can run efficiently on an embedded system in the wild. This paper proposes an automatic detection algorithm for the Bela embedded Linux device for wildlife monitoring. The algorithm achieves good quality recognition, efficiently running on continuously streamed data on a commercially available platform. The program is capable of computing on-board detection using convolutional neural networks (CNNs) with an AUC score of 82.5% on the testing set of an international data challenge. This paper details how the model is exported to work on the Bela Mini in C++, with the spectrogram generation and the implementation of the feed-forward network, and evaluates its performance on the Bird Audio Detection challenge 2018 DCASE data. © 2020 IEEE.},
  keywords = {Birds; C++ (programming language); Computer operating systems; Convolutional neural networks; Deep learning; Embedded systems; Feedforward neural networks; Software testing; Speech communication; Audio detection; Automatic detection algorithms; Data challenges; Embedded Linux; Feed-forward network; Quality recognition; Sound detection; Wildlife monitoring; Audio signal processing},
  doi      = {10.1109/ICASSP40776.2020.9053533},
  url      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089232175&doi=10.1109%2fICASSP40776.2020.9053533&partnerID=40&md5=40d0d4b5469a5c3b7cc13b7b038a865b}
}


@article{ref14,
  title    = {Automatic bird song and syllable segmentation with an open-source deep-learning object detection method – a case study in the collared flycatcher (Ficedula albicollis)},
  author   = {Zsebők S.; Nagy-Egri M.F.; Barnaföldi G.G.; Laczi M.; Nagy G.; Vaskuti É.; Garamszegi L.Z.},
  year     = {2019},
  journal  = {Ornis Hungarica},
  abstract = {The bioacoustic analyses of animal sounds result in an enormous amount of digitized acoustic data, and we need effective automatic processing to extract the information content of the recordings. Our research focuses on the song of Collared Flycatcher (Ficedula albicollis) and we are interested in the evolution of acoustic signals. During the last 20 years, we obtained hundreds of hours of recordings of bird songs collected in natural environment, and there is a permanent need for the automatic process of recordings. In this study, we chose an open-source, deep-learning image detection system to (1) find the species-specific songs of the Collared Flycatcher on the recordings and (2) to detect the small, discrete elements so-called syllables within the song. For these tasks, we first transformed the acoustic data into spectrogram images, then we trained two deep-learning models separately on our manually segmented database. The resulted models detect the songs with an intersection of union higher than 0.8 and the syllables higher than 0.7. This technique anticipates an order of magnitude less human effort in the acoustic processing than the manual method used before. Thanks to the new technique, we are able to address new biological questions that need large amount of acoustic data. © 2019, BirdLife Hungary. All rights reserved.},
  keywords = {},
  doi      = {10.2478/orhu-2019-0015},
  url      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076776803&doi=10.2478%2forhu-2019-0015&partnerID=40&md5=c5a93f2d7b3076bfa1612162a9988d2c}
}


@article{ref15,
  title    = {Bat detective—Deep learning tools for bat acoustic signal detection},
  author   = {Mac Aodha O.; Gibb R.; Barlow K.E.; Browning E.; Firman M.; Freeman R.; Harder B.; Kinsey L.; Mead G.R.; Newson S.E.; Pandourski I.; Parsons S.; Russ J.; Szodoray-Paradi A.; Szodoray-Paradi F.; Tilova E.; Girolami M.; Brostow G.; Jones K.E.},
  year     = {2018},
  journal  = {PLoS Computational Biology},
  abstract = {Passive acoustic sensing has emerged as a powerful tool for quantifying anthropogenic impacts on biodiversity, especially for echolocating bat species. To better assess bat population trends there is a critical need for accurate, reliable, and open source tools that allow the detection and classification of bat calls in large collections of audio recordings. The majority of existing tools are commercial or have focused on the species classification task, neglecting the important problem of first localizing echolocation calls in audio which is particularly problematic in noisy recordings. We developed a convolutional neural network based open-source pipeline for detecting ultrasonic, full-spectrum, search-phase calls produced by echolocating bats. Our deep learning algorithms were trained on full-spectrum ultrasonic audio collected along road-transects across Europe and labelled by citizen scientists from www.batdetective.org. When compared to other existing algorithms and commercial systems, we show significantly higher detection performance of search-phase echolocation calls with our test sets. As an example application, we ran our detection pipeline on bat monitoring data collected over five years from Jersey (UK), and compared results to a widely-used commercial system. Our detection pipeline can be used for the automatic detection and monitoring of bat populations, and further facilitates their use as indicator species on a large scale. Our proposed pipeline makes only a small number of bat specific design decisions, and with appropriate training data it could be applied to detecting other species in audio. A crucial novelty of our work is showing that with careful, non-trivial, design and implementation considerations, state-of-the-art deep learning methods can be used for accurate and efficient monitoring in audio. © 2018 Mac Aodha et al.},
  keywords = {Algorithms; Animals; Chiroptera; Computational Biology; Echolocation; Endangered Species; Environmental Monitoring; Machine Learning; Neural Networks (Computer); Signal Processing, Computer-Assisted; Zoology; Audio systems; Deep learning; Learning algorithms; Neural networks; Search engines; Signal detection; Ultrasonic applications; Acoustic sensing; Acoustic signal detection; Anthropogenic impacts; Commercial systems; Echolocation calls; Full-spectrum; Learning tool; Open source tools; Passive acoustics; Search phasis; article; echolocation; human; indicator organism; Jersey; learning algorithm; nervous system; nonhuman; pipeline; scientist; signal detection; ultrasound; algorithm; animal; artificial neural network; bat; biology; classification; endangered species; environmental monitoring; machine learning; physiology; procedures; signal processing; zoology; Pipelines},
  doi      = {10.1371/journal.pcbi.1005995},
  url      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044788623&doi=10.1371%2fjournal.pcbi.1005995&partnerID=40&md5=eb11d274ba0c0d1b6c99be496b0ed05b}
}


@misc{ref16,
  title    = {Open‐source workflow approaches to passive acoustic monitoring of bats},
  author   = {SMM Brinkløv, J Macaulay, C Bergler, ...},
  year     = {2023},
  journal  = {Methods in Ecology …},
  abstract = {… complete acoustic detection and classification workflows for bat PAM … information that can be extracted from acoustic recordings. In particular, … 1.3 Automatic detection and classification …},
  keywords = {},
  doi      = {10.1111/2041-210X.14131},
  url      = {https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.14131}
}


@misc{ref17,
  title    = {Passive acoustic monitoring in ecology and conservation.},
  author   = {E Browning, R Gibb, P Glover-Kapfer, KE Jones},
  year     = {2017},
  journal  = {},
  abstract = {… Most bats vocalise in the ultrasonic spectrum, meaning that specialised ultrasonic bat detectors are required to detect and record their calls. The simplest are heterodyne detectors, …},
  keywords = {},
  doi      = {},
  url      = {https://repository.oceanbestpractices.org/handle/11329/1370}
}


@article{ref18,
  title    = {Passive acoustic monitoring of animal populations with transfer learning},
  author   = {E Dufourq, C Batist, R Foquet, I Durbach},
  year     = {2022},
  journal  = {Ecological Informatics},
  abstract = {… and requires knowledge of machine learning. Furthermore, … learning can be used for passive acoustic monitoring (PAM), to … architectures across 4 passive acoustic datasets that target …},
  keywords = {},
  doi      = {},
  url      = {https://www.sciencedirect.com/science/article/pii/S1574954122001388}
}


@misc{ref19,
  title    = {Automated bioacoustics: methods in ecology and conservation and their potential for animal welfare monitoring},
  author   = {MP Mcloughlin, R Stewart, ...},
  year     = {2019},
  journal  = {Journal of the Royal …},
  abstract = {… species and animal location is often referred to as passive acoustic monitoring [52,53,98]. … Indicator bats program: a system for the global acoustic monitoring of bats. In Biodiversity …},
  keywords = {},
  doi      = {10.1098/rsif.2019.0225},
  url      = {https://royalsocietypublishing.org/doi/abs/10.1098/rsif.2019.0225}
}


@misc{ref20,
  title    = {Using software-based acoustic detection and supporting tools to enable large-scale environmental monitoring},
  author   = {P Prince},
  year     = {2019},
  journal  = {},
  abstract = {… Manual inspection and automatic detection algorithms can … Researchers utilising passive acoustic monitoring in this way … variety of different ultrasonic acoustic recorders available for bat …},
  keywords = {},
  doi      = {},
  url      = {https://eprints.soton.ac.uk/438947/}
}


@article{ref21,
  title    = {Monitoring of a nearshore small dolphin species using passive acoustic platforms and supervised machine learning techniques},
  author   = {F Caruso, L Dong, M Lin, M Liu, Z Gong, ...},
  year     = {2020},
  journal  = {Frontiers in Marine …},
  abstract = {… Passive acoustic monitoring (PAM… automatic detection of the highest number of clicks. This result confirmed the potential applications of PAM using both automatic and manual methods …},
  keywords = {},
  doi      = {10.3389/fmars.2020.00267},
  url      = {https://www.frontiersin.org/articles/10.3389/fmars.2020.00267/full}
}


@article{ref22,
  title    = {Methods for processing and analyzing passive acoustic monitoring data: An example of song recognition in western black-crested gibbons},
  author   = {X Zhou, K Hu, Z Guan, C Yu, S Wang, M Fan, Y Sun, ...},
  year     = {2023},
  journal  = {Ecological …},
  abstract = {… Our best model converts acoustic recordings into … In the four consecutive years of the acoustic monitoring system deployed … We demonstrate that passive acoustic monitoring combined …},
  keywords = {},
  doi      = {},
  url      = {https://www.sciencedirect.com/science/article/pii/S1470160X23010506}
}


@misc{ref23,
  title    = {Passive acoustic monitoring and audio subsampling: optimizing autonomous methods for avian biodiversity assessments},
  author   = {TW Burfin},
  year     = {2022},
  journal  = {},
  abstract = {… acoustic monitoring. It also intends to improve the efficiency of manual processing of acoustic data … Lastly, it tries to facilitate future protocol designs of autonomous acoustic methods in …},
  keywords = {},
  doi      = {},
  url      = {https://repositorio.ul.pt/handle/10451/54427}
}


@misc{ref24,
  title    = {Tadarida: A toolbox for animal detection on acoustic recordings},
  author   = {Y Bas, D Bas, JF Julien},
  year     = {2017},
  journal  = {Journal of …},
  abstract = {… exponential development of Passive Acoustic Monitoring (PAM) of a … sound data on bats and bush-crickets, we needed to … the whole process: automatic detection and labelling to build …},
  keywords = {},
  doi      = {},
  url      = {https://account.openresearchsoftware.metajnl.com/index.php/up-j-jors/article/view/jors.154}
}


@article{ref25,
  title    = {Automatic bat call classification using transformer networks},
  author   = {F Fundel, DA Braun, S Gottwald},
  year     = {2023},
  journal  = {Ecological Informatics},
  abstract = {… method of monitoring bats is based on recording and categorizing their ultrasonic echolocation calls. As classifying hours of recordings manually is tedious, automatic detection and …},
  keywords = {},
  doi      = {},
  url      = {https://www.sciencedirect.com/science/article/pii/S1574954123003175}
}


@article{ref26,
  title    = {Automated detection and detection range of primate duets: a case study of the red titi monkey (Plecturocebus discolor) using passive acoustic monitoring},
  author   = {SM van Kuijk, S O'Brien, DJ Clink, JG Blake, ...},
  year     = {2023},
  journal  = {Frontiers in Ecology …},
  abstract = {… In this study, we demonstrate that passive acoustic monitoring together with an automated detection algorithm can be an effective method to study duetting behavior in titi monkeys and …},
  keywords = {},
  doi      = {10.3389/fevo.2023.1173722},
  url      = {https://www.frontiersin.org/articles/10.3389/fevo.2023.1173722/full}
}


@misc{ref27,
  title    = {Estimating animal population density using passive acoustics},
  author   = {TA Marques, L Thomas, SW Martin, ...},
  year     = {2013},
  journal  = {Biological …},
  abstract = {… acoustic data might contain useful information about animal density has evolved over the last few decades. Passive acoustic monitoring (… Automatic detection and statistical classification …},
  keywords = {},
  doi      = {10.1111/brv.12001},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/brv.12001}
}


@misc{ref28,
  title    = {Aggregated time‐series features boost species‐specific differentiation of true and false positives in passive acoustic monitoring of bird assemblages},
  author   = {D Singer, J Hagge, J Kamp, ...},
  year     = {2024},
  journal  = {Remote Sensing in …},
  abstract = {Passive acoustic monitoring (PAM) has gained increasing popularity to study behaviour, habitat preferences, distribution and community assembly of birds and other animals. …},
  keywords = {},
  doi      = {10.1002/rse2.385},
  url      = {https://zslpublications.onlinelibrary.wiley.com/doi/abs/10.1002/rse2.385}
}


@article{ref29,
  title    = {Improving deep learning acoustic classifiers with contextual information for wildlife monitoring},
  author   = {L Jeantet, E Dufourq},
  year     = {2023},
  journal  = {Ecological Informatics},
  abstract = {… large acoustic datasets obtained from passive acoustic monitoring … in improving the automatic detection of vocalizations from the … Passive acoustic monitoring was employed to study the …},
  keywords = {},
  doi      = {},
  url      = {https://www.sciencedirect.com/science/article/pii/S1574954123002856}
}


@misc{ref30,
  title    = {Evaluating factors affecting species detection using passive acoustic monitoring in neotropical forests: a playback experiment},
  author   = {A Hutschenreiter, JR Sosa-López, ...},
  year     = {2023},
  journal  = {Bioacoustics},
  abstract = {… Passive acoustic monitoring (PAM) has become a popular approach for terrestrial species … Our study sheds light on factors influencing acoustic signal detectability and emphasises …},
  keywords = {},
  doi      = {10.1080/09524622.2023.2246413},
  url      = {https://www.tandfonline.com/doi/abs/10.1080/09524622.2023.2246413}
}


@book{ref31,
  title    = {Acoustically assessing apes: chimpanzee conservation with passive acoustic monitoring},
  author   = {AS Crunchant},
  year     = {2020},
  journal  = {},
  abstract = {… The employment of passive acoustic monitoring to establish a better understanding of acoustic communities has emerged as an important tool in assessing overall diversity and habitat …},
  keywords = {},
  doi      = {},
  url      = {https://search.proquest.com/openview/be5eb103d5a33523687ddc0aeb0b988a/1?pq-origsite=gscholar&cbl=2026366&diss=y}
}


@book{ref32,
  title    = {MonitoR: automation tools for landscape-scale acoustic monitoring},
  author   = {J Katz},
  year     = {2015},
  journal  = {},
  abstract = {… Unlike active acoustic monitoring (playback and response), passive acoustic monitoring uses the … Supporting the BRP’s lightly pessimistic view on automatic detection is the fact that few …},
  keywords = {},
  doi      = {},
  url      = {https://search.proquest.com/openview/4fd8682b1ae5175fd67b3ae1058ae923/1?pq-origsite=gscholar&cbl=18750}
}


@misc{ref33,
  title    = {Automatic acoustic detection of birds through deep learning: the first bird audio detection challenge},
  author   = {D Stowell, MD Wood, H Pamuła, ...},
  year     = {2019},
  journal  = {Methods in Ecology …},
  abstract = {… , and thus, passive acoustic monitoring is highly appropriate. Yet acoustic monitoring is often held … How can we improve automatic detection on these weak sounds? Applying source …},
  keywords = {},
  doi      = {10.1111/2041-210X.13103},
  url      = {https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13103}
}


@misc{ref34,
  title    = {Expert-driven development of conservation technologies to close knowledge gaps in small animal research},
  author   = {J Gottwald},
  year     = {2022},
  journal  = {},
  abstract = {… to trained machine learning models for classifying behaviours in radio-tracking data and bat … substitute labour-intensive and error prone manual methods in the context of environmental …},
  keywords = {},
  doi      = {},
  url      = {https://archiv.ub.uni-marburg.de/diss/z2023/0087}
}


@misc{ref35,
  title    = {Automated detection and classification of cetacean acoustic signals},
  author   = {P Best},
  year     = {2022},
  journal  = {},
  abstract = {… Passive Acoustic Monitoring (PAM) is a field of bioacoustic … recording hardware, to signal processing and statistical analysis. … the development of automatic detection mechanisms. With …},
  keywords = {},
  doi      = {},
  url      = {https://hal.science/tel-03826638/}
}


@misc{ref36,
  title    = {Birds, bats and beyond: Evaluating generalization in bioacoustics models},
  author   = {B Van Merriënboer, J Hamer, V Dumoulin, ...},
  year     = {2024},
  journal  = {Frontiers in Bird …},
  abstract = {… In the context of passive acoustic monitoring (PAM) better models are needed to reliably gain insights from large amounts of raw, unlabeled data. Bioacoustics foundation models, which …},
  keywords = {},
  doi      = {10.3389/fbirs.2024.1369756},
  url      = {https://www.frontiersin.org/articles/10.3389/fbirs.2024.1369756/full}
}


@misc{ref37,
  title    = {Acoustic monitoring of wildlife in inaccessible areas and automatic detection of bird songs from continuous recordings},
  author   = {EV Hockman},
  year     = {2018},
  journal  = {},
  abstract = {… acoustic monitoring techniques require innovative methods to extract and utilize data from acoustic … The autonomous aerial acoustic recording system (AAARS) was a UAV developed at …},
  keywords = {},
  doi      = {},
  url      = {https://trace.tennessee.edu/utk_graddiss/4874/}
}


@misc{ref38,
  title    = {Automated bird acoustic detection at Las Arrieras Nature Reserve in Sarapiquí, Costa Rica},
  author   = {R Vargas-Masís, D Segura-Sequeira, ...},
  year     = {2022},
  journal  = {2022 IEEE 4th …},
  abstract = {… Passive acoustic monitoring has been used for a long time to … bats have been the focus on automatic detection studies using vocalizations [9]. To achieve this, various machine learning …},
  keywords = {},
  doi      = {},
  url      = {https://ieeexplore.ieee.org/abstract/document/10032472/}
}


@misc{ref39,
  title    = {Processing of bowhead whale vocalisations and handling of acoustic recording equipment},
  author   = {JN Aubach Ratcliffe},
  year     = {2023},
  journal  = {},
  abstract = {… , the application of passive acoustic monitoring (PAM) has proven to … context, the automatic detection of vocalizations would … whales to the ultrasonic signals of bats and toothed whales. …},
  keywords = {},
  doi      = {},
  url      = {https://upcommons.upc.edu/handle/2117/397581}
}


@misc{ref40,
  title    = {Acoustic monitoring for conservation in tropical forests: examples from forest elephants},
  author   = {PH Wrege, ED Rowland, S Keen, ...},
  year     = {2017},
  journal  = {Methods in Ecology and …},
  abstract = {… Passive acoustic monitoring is a viable and cost-effective tool for … Automatic detection is critical for large-scale studies but the … Passive acoustic monitoring should be added to any …},
  keywords = {},
  doi      = {10.1111/2041-210X.12730},
  url      = {https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.12730}
}


@article{ref41,
  title    = {Time of night and moonlight structure vertical space use by insectivorous bats in a Neotropical rainforest: an acoustic monitoring study},
  author   = {DGE Gomes, G Appel, JR Barber},
  year     = {2020},
  journal  = {PeerJ},
  abstract = {… passive acoustic monitoring to explore how Neotropical bats use space over time. While bats generally were more active above the forest canopy, we show that individual groups of bats …},
  keywords = {},
  doi      = {},
  url      = {https://peerj.com/articles/10591/}
}


@article{ref42,
  title    = {Passive acoustic methods for tracking the 3D movements of small cetaceans around marine structures},
  author   = {D Gillespie, L Palmer, J Macaulay, C Sparling, ...},
  year     = {2020},
  journal  = {PLoS …},
  abstract = {… detect and track birds and bats around windfarms to inform estimates … Implementing fully automatic detection systems across all … Passive acoustic monitoring alone is unable to localise …},
  keywords = {},
  doi      = {},
  url      = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0229058}
}


@misc{ref43,
  title    = {Time and habitat structure shape insect acoustic activity in the Amazon},
  author   = {LA Do Nascimento, ...},
  year     = {2024},
  journal  = {… of the Royal …},
  abstract = {… passive acoustic monitoring at 141 sites (eight habitats) to investigate insect acoustic … , or predation pressure (eg birds, bats) may have an impact on the acoustic activity of insects [19,55]…},
  keywords = {},
  doi      = {10.1098/rstb.2023.0112},
  url      = {https://royalsocietypublishing.org/doi/abs/10.1098/rstb.2023.0112}
}


@article{ref44,
  title    = {Automated visual large scale monitoring of faunal biodiversity},
  author   = {B Radig, P Bodesheim, D Korsch, J Denzler, ...},
  year     = {2021},
  journal  = {Pattern Recognition and …},
  abstract = {… reaction of the sensor element and the internal signal processing. In this time, animals may … Therefore, novelty detection is relevant [2, 3] which allows for automatic detection of animals …},
  keywords = {},
  doi      = {10.1134/S1054661821030214},
  url      = {https://link.springer.com/article/10.1134/S1054661821030214}
}


@misc{ref45,
  title    = {Automated detection of Bornean white-bearded gibbon (Hylobates albibarbis) vocalisations using an open-source framework for deep learning},
  author   = {AF Owens, KJ Hockings, MA Imron, S Madhusudhana, ...},
  year     = {2024},
  journal  = {bioRxiv},
  abstract = {… Passive acoustic monitoring is a promising tool for monitoring … Bat detective—Deep learning tools for bat acoustic signal … Improve automatic detection of animal call sequences 551 with …},
  keywords = {},
  doi      = {10.1101/2024.04.15.589517.abstract},
  url      = {https://www.biorxiv.org/content/10.1101/2024.04.15.589517.abstract}
}


@misc{ref46,
  title    = {… short interclick intervals from the clicks of Ganges river dolphins (Platanista gangetica gangetica) recorded by a passive acoustic monitoring system using hydrophone …},
  author   = {H Sugimatsu, J Kojima, T Ura, R Bahl, ...},
  year     = {2014},
  journal  = {Marine Technology …},
  abstract = {… has been carried out using a passive acoustic monitoring (PAM) system. During monitoring … 6 to 12 ms) were concurrently found from the acoustic data corresponding to the period. Click …},
  keywords = {},
  doi      = {},
  url      = {https://www.ingentaconnect.com/content/mts/mtsj/2014/00000048/00000003/art00016}
}


@misc{ref47,
  title    = {Passive Acoustic Monitoring in Ranomafana National Park},
  author   = {W Slingerland},
  year     = {2021},
  journal  = {},
  abstract = {… dataset gathered through Passive Acoustic Monitoring (PAM) to … respectively, and compared the acoustic niche space of different … bird species showed little acoustic niche overlap in the …},
  keywords = {},
  doi      = {},
  url      = {https://studenttheses.uu.nl/handle/20.500.12932/299}
}


@misc{ref48,
  title    = {Echolocation calls of Natalus primus (Chiroptera: Natalidae): Implications for conservation monitoring of this species},
  author   = {L Sanchez, CR Moreno, EC Mora},
  year     = {2017},
  journal  = {Cogent Biology},
  abstract = {… allow conducting passive acoustic monitoring, constituting a … Natalus primus is a vulnerable bat species reported only in a … primus among other bat species when conducting acoustic …},
  keywords = {},
  doi      = {10.1080/23312025.2017.1355027},
  url      = {https://www.tandfonline.com/doi/abs/10.1080/23312025.2017.1355027}
}


@misc{ref49,
  title    = {Minke whale acoustic behavior and multi-year seasonal and diel vocalization patterns in Massachusetts Bay, USA},
  author   = {D Risch, CW Clark, PJ Dugan, M Popescu, ...},
  year     = {2013},
  journal  = {Marine Ecology …},
  abstract = {… In recent years, passive acoustic monitoring (PAM) has … , fundamental knowledge on their acoustic behavior is still missing, … Distributions are based on analyses of automatic detection …},
  keywords = {},
  doi      = {},
  url      = {https://www.int-res.com/abstracts/meps/v489/p279-295/}
}


@book{ref50,
  title    = {Passive acoustic monitoring of toothed whales, with implications for mitigation, management and biology},
  author   = {LA Kyhn},
  year     = {2011},
  journal  = {},
  abstract = {… passive acoustic monitoring provides continuous monitoring in time in contrast to the snap-… on the acoustics of NBHF species with relevance for aspects of passive acoustic monitoring, …},
  keywords = {},
  doi      = {},
  url      = {https://www2.dmu.dk/Pub/PHD_LAK.pdf}
}


@misc{ref51,
  title    = {Diversity and plasticity of vocalisations in an elusive and arboreal small mammal: the edible dormouse (Glis glis)},
  author   = {C Bartrina, C Llanos-Guerrero, N Valls, L Freixas, ...},
  year     = {2024},
  journal  = {Bioacoustics},
  abstract = {… captivity, suggesting that with passive acoustic monitoring (Browning et al. Citation… automatic detection algorithms in dormice would not only simplify and facilitate the process of acoustic …},
  keywords = {},
  doi      = {10.1080/09524622.2024.2353651},
  url      = {https://www.tandfonline.com/doi/abs/10.1080/09524622.2024.2353651}
}


@misc{ref52,
  title    = {Sound evidence for biodiversity monitoring},
  author   = {JH Rasmussen, D Stowell, EF Briefer},
  year     = {2024},
  journal  = {Science},
  abstract = {… birds and bats (such as BirdNET and BTO Acoustic Pipeline). … in the oceans, called passive acoustic monitoring (PAM) (12). … promising results for automatic detection of social calls (13). …},
  keywords = {},
  doi      = {10.1126/science.adh2716},
  url      = {https://www.science.org/doi/abs/10.1126/science.adh2716}
}


@article{ref53,
  title    = {Long-term monitoring of dolphin biosonar activity in deep pelagic waters of the Mediterranean Sea},
  author   = {F Caruso, G Alonge, G Bellia, E De Domenico, ...},
  year     = {2017},
  journal  = {Scientific Reports},
  abstract = {… Toward that goal, we developed and tested an automatic detection method for dolphin biosonar … Passive acoustic monitoring is rapidly growing as a relatively low-cost, high-resolution …},
  keywords = {},
  doi      = {},
  url      = {https://www.nature.com/articles/s41598-017-04608-6}
}


@misc{ref54,
  title    = {… seasonal occurrence of sympatric killer whale lineages in waters off Southern Vancouver Island and Washington State, as determined by passive acoustic monitoring},
  author   = {A Riera},
  year     = {2012},
  journal  = {},
  abstract = {… This study shows the effectiveness of using passive acoustic monitoring to provide important information about killer whale seasonal occurrence and provides a quantitative evaluation …},
  keywords = {},
  doi      = {},
  url      = {http://dspace.library.uvic.ca/handle/1828/4125}
}


@article{ref55,
  title    = {The effect of local land use on aerial insectivorous bats (Chiroptera) within the two dominating crop types in the Northern-Caribbean lowlands of Costa Rica},
  author   = {P Alpizar, B Rodriguez-Herrera, K Jung},
  year     = {2019},
  journal  = {PLoS One},
  abstract = {… Bat occurrence was assessed using passive acoustic monitoring, which is a non-invasive … bat assemblage and activity of a given site. We first used an automatic detection system for bat …},
  keywords = {},
  doi      = {},
  url      = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0210364}
}


@article{ref56,
  title    = {Long-Range Bird Species Identification Using Directional Microphones and CNNs},
  author   = {T Garcia, L Pina, M Robb, J Maria, R May, ...},
  year     = {2024},
  journal  = {Machine Learning and …},
  abstract = {… We developed a directional microphone acoustic sensor, … the system in terms of the acoustic response (sound quality) and … How AudioMoth-based passive acoustic monitoring is …},
  keywords = {},
  doi      = {},
  url      = {https://www.mdpi.com/2504-4990/6/4/115}
}


@misc{ref57,
  title    = {Amazonian soundscapes: unravelling the secrets of insect acoustic niches in diverse habitats},
  author   = {L Do Nascimento, C Pérez-Granados, JBR Alencar, ...},
  year     = {2023},
  journal  = {},
  abstract = {… Here, we performed passive acoustic monitoring at 141 sites (… Bat predation and its influence on calling behavior in … Passive acoustic monitoring and automatic detection of diel …},
  keywords = {},
  doi      = {},
  url      = {https://ecoevorxiv.org/repository/view/6292/}
}


@article{ref58,
  title    = {Open-source machine learning BANTER acoustic classification of beaked whale echolocation pulses},
  author   = {S Rankin, T Sakai, FI Archer, J Barlow, D Cholewiak, ...},
  year     = {2024},
  journal  = {Ecological …},
  abstract = {… Passive acoustic monitoring is increasingly used for assessing populations of marine mammals; however, analysis of large datasets is limited by our ability to easily classify sounds …},
  keywords = {},
  doi      = {},
  url      = {https://www.sciencedirect.com/science/article/pii/S1574954124000530}
}


@article{ref59,
  title    = {Call recognition and individual identification of fish vocalizations based on automatic speech recognition: an example with the Lusitanian toadfish},
  author   = {M Vieira, PJ Fonseca, M Amorim, ...},
  year     = {2015},
  journal  = {The Journal of the …},
  abstract = {… Fish often use acoustic signals during mating and territorial defense and are probably the … best of our knowledge, no automatic detection machine learning HMM-based application to …},
  keywords = {},
  doi      = {},
  url      = {https://pubs.aip.org/asa/jasa/article/138/6/3941/630842}
}


@misc{ref60,
  title    = {BAT-CNN: BirdNet Assisted Training for CNN},
  author   = {S Salini, K Suresh},
  year     = {2024},
  journal  = {2024 International Conference on …},
  abstract = {… applied to large passive acoustic monitoring datasets. A dataset of seven acoustic scenes was used … Jetté, “Artificial intelligence (birdnet) supplements manual methods to maximize bird …},
  keywords = {},
  doi      = {},
  url      = {https://ieeexplore.ieee.org/abstract/document/10617409/}
}


@misc{ref61,
  title    = {Introduction to Applications on Vertebrate Vocalisation},
  author   = {R Murugaiya, MM Mahagammulle Gamage, ...},
  year     = {2022},
  journal  = {Acoustic-Based …},
  abstract = {… with active and passive acoustic monitoring can contribute to … both active and passive acoustic monitoring applications, which … of the bats by analysing the same call vocalisations. …},
  keywords = {},
  doi      = {10.1007/978-3-030-85773-8_1},
  url      = {https://link.springer.com/chapter/10.1007/978-3-030-85773-8_1}
}


@misc{ref62,
  title    = {Exploring the potential of occupancy modelling using passive acoustics in Coua gigas and Coua coquereli},
  author   = {C Jordan, M Markolf},
  year     = {2023},
  journal  = {Madagascar Conservation &Development},
  abstract = {… negatives created by the automatic detection process lead to … demonstrated that passive acoustic monitoring is suitable for … few studies on passive acoustic monitoring in bird species in …},
  keywords = {},
  doi      = {},
  url      = {https://www.ajol.info/index.php/mcd/article/view/262770}
}


@misc{ref63,
  title    = {Acoustic detections of arctic marine mammals near ulukhaktok, northwest territories, Canada},
  author   = {WD Halliday, MK Pine, SJ Insley, ...},
  year     = {2019},
  journal  = {Canadian Journal of …},
  abstract = {… We use passive acoustic monitoring to examine the presence of marine mammals near … based on the presence of at least one automatic detection in a file versus the actual presence of …},
  keywords = {},
  doi      = {10.1139/cjz-2018-0077},
  url      = {https://cdnsciencepub.com/doi/abs/10.1139/cjz-2018-0077}
}


@misc{ref64,
  title    = {Machine learning analysis reveals relationship between pomacentrid calls and environmental cues},
  author   = {JE Munger, DP Herrera, SM Haver, ...},
  year     = {2022},
  journal  = {Marine Ecology …},
  abstract = {… —to demonstrate the applicability of machine learning in fish acoustics and ecology. The … This research has broad implications for state-of-the-art acoustic analysis and promises to …},
  keywords = {},
  doi      = {},
  url      = {https://www.int-res.com/abstracts/meps/v681/p197-210/}
}


@article{ref65,
  title    = {Introducing NMMF WAMS, an open-source PAMGuard plug-in, and some pilot data for its use as a welfare acoustic monitoring system},
  author   = {B Jones, M Oswald, S Tufano, M Baird, ...},
  year     = {2020},
  journal  = {Sound Health},
  abstract = {… While the use of passive acoustic monitoring systems … acoustic behavior by providing hourly counts of acoustic detections and comparison to historical data. Having a validated acoustic …},
  keywords = {},
  doi      = {},
  url      = {https://scholar.archive.org/work/shsgi66worbnbj5nkggkh25kpe/access/wayback/https://assets.researchsquare.com/files/rs-55999/v1/1331ee86-ff91-44d5-b53f-0851a90a04dc.pdf}
}


@misc{ref66,
  title    = {Computing biodiversity change via a soundscape monitoring network},
  author   = {TH Lin, Y Tsao, YH Wang, HW Yen, ...},
  year     = {2017},
  journal  = {… Annual Conference and …},
  abstract = {… acoustic monitoring has been widely employed to study the occurrence and behavior of vocalizing animals, such as birds, bats, fish, … However, the automatic detection and classification …},
  keywords = {},
  doi      = {},
  url      = {https://ieeexplore.ieee.org/abstract/document/8203533/}
}


@article{ref67,
  title    = {A hidden Markov model approach to indicate Bryde's whale acoustics},
  author   = {RL Putland, L Ranjard, R Constantine, CA Radford},
  year     = {2018},
  journal  = {Ecological Indicators},
  abstract = {… Long-term passive acoustic monitoring efforts have become … Acoustic data was collected at a single listening station in … using HMMs on long-term acoustic datasets. The method has the …},
  keywords = {},
  doi      = {},
  url      = {https://www.sciencedirect.com/science/article/pii/S1470160X17305939}
}


@article{ref68,
  title    = {The use of acoustic analyses to evaluate ecological and social impacts of habitat degradation in contemporary conservation biology},
  author   = {P Moscoso Rosero},
  year     = {2018},
  journal  = {},
  abstract = {… through the acoustic indices. To tackle this issue, I observed that the tool for automatic detection of … level (acoustic indices) and individual level (automatic detection of indicator species) …},
  keywords = {},
  doi      = {},
  url      = {https://core.ac.uk/download/pdf/161102660.pdf}
}


@book{ref69,
  title    = {Acoustic-Based Applications for Vertebrate Vocalization},
  author   = {R Murugaiya, MMM Gamage, K Murugiah, M Perumal},
  year     = {2021},
  journal  = {},
  abstract = {… with active and passive acoustic monitoring can contribute to … active and passive acoustic monitoring applications, which … the everyday interactions of the bats by analysing the same …},
  keywords = {},
  doi      = {10.1007/978-3-030-85773-8},
  url      = {https://link.springer.com/content/pdf/10.1007/978-3-030-85773-8.pdf}
}


@misc{ref70,
  title    = {An unsupervised Hidden Markov Model-based system for the detection and classification of blue whale vocalizations off Chile},
  author   = {SJ Buchan, R Mahú, J Wuth, N Balcazar-Cabrera, ...},
  year     = {2020},
  journal  = {Bioacoustics},
  abstract = {… acoustic monitoring (PAM) data using Hidden Markov Model technology implemented with a state-of-the-art machine learning … achieve a robust automatic detection method that neither …},
  keywords = {},
  doi      = {10.1080/09524622.2018.1563758},
  url      = {https://www.tandfonline.com/doi/abs/10.1080/09524622.2018.1563758}
}


@misc{ref71,
  title    = {A virtual auditory environment for investigating the auditory signal processing of realistic sounds},
  author   = {SE Favrot, J Buchholz},
  year     = {2008},
  journal  = {Journal of the Acoustical Society of America},
  abstract = {… Automatic detection of the longdistance propagating communication calls are desirable for implementing passive acoustic monitoring (… by bats, we need to precisely measure acoustic …},
  keywords = {},
  doi      = {},
  url      = {https://orbit.dtu.dk/en/publications/a-virtual-auditory-environment-for-investigating-the-auditory-sig}
}


@article{ref72,
  title    = {Developing technologies for Agri-environment monitoring},
  author   = {DB Roy, C Abrahams, T August, J Christelow, ...},
  year     = {2022},
  journal  = {},
  abstract = {… Trial the use of acoustic indices in a range of AES habitats and landscapes. Address how acoustic recorders should most effectively be deployed to capture relevant data in the UK …},
  keywords = {},
  doi      = {},
  url      = {https://eu-cap-network.ec.europa.eu/sites/default/files/publications/2024-09/developing-technologies-for-agri-environment-monitoring.pdf}
}


@misc{ref73,
  title    = {Soundbay: Deep Learning Framework for Marine Mammals and Bioacoustic Research},
  author   = {N Bressler, M Faran, A Galor, MM Michelashvili, ...},
  year     = {2023},
  journal  = {arXiv preprint arXiv …},
  abstract = {… Automatic detection and compression for passive acoustic monitoring of the african forest elephant. … Automated detection of hainan gibbon calls for passive acoustic monitoring. Remote …},
  keywords = {},
  doi      = {},
  url      = {https://arxiv.org/abs/2311.04343}
}


@misc{ref74,
  title    = {System and methods for processing and the visualization of bioaccoustical information},
  author   = {I Urazghildiiev},
  year     = {2019},
  journal  = {US Patent 10,222,493},
  abstract = {… certain embodiments of the present invention permit a user to more rapidly analyze a large body of acoustic data recorded from the passive acoustic monitoring of an area and, through …},
  keywords = {},
  doi      = {},
  url      = {https://patents.google.com/patent/US10222493B2/en}
}


@article{ref75,
  title    = {Convolutional neural networks for the identification of African lions from individual vocalizations},
  author   = {M Trapanotto, L Nanni, S Brahnam, X Guo},
  year     = {2022},
  journal  = {Journal of Imaging},
  abstract = {… The classification of vocal individuality for passive acoustic monitoring (PAM) and census of … identification in [44], a tiny CNN for bat echolocation calls was developed in [45], and a CNN …},
  keywords = {},
  doi      = {},
  url      = {https://www.mdpi.com/2313-433X/8/4/96}
}


@article{ref76,
  title    = {Acoustic localization at large scales: a promising method for grey wolf monitoring},
  author   = {M Papin, J Pichenot, F Guérold, E Germain},
  year     = {2018},
  journal  = {Frontiers in Zoology},
  abstract = {… Passive acoustic monitoring is being used increasingly to study species that produce … As the signal-to-noise ratio was too low to use cross-correlation or automatic detection algorithms, …},
  keywords = {},
  doi      = {10.1186/s12983-018-0260-2},
  url      = {https://link.springer.com/article/10.1186/s12983-018-0260-2}
}


@article{ref77,
  title    = {Species identification and measurement of activity in odontocete species of Palmyra Atoll by acoustic monitoring},
  author   = {S Baumann-Pickering},
  year     = {2009},
  journal  = {},
  abstract = {… Autonomous long-term passive acoustic monitoring is a viable … behavior in relation to echolocating dolphins and bats. … Despite the automatic detection that also counted sequences …},
  keywords = {},
  doi      = {},
  url      = {https://www.cetus.ucsd.edu/docs/dissertations/Baumann-PickeringPhD2009.pdf}
}


@article{ref78,
  title    = {AVIAN BIOLOGY},
  author   = {N Priyadarshani, S Marsland, I Castro},
  year     = {2017},
  journal  = {},
  abstract = {… considerable knowledge in signal processing and underlying … ) methods of passive acoustic monitoring are required. We … of their effectiveness to automatic detection of putative calls. …},
  keywords = {},
  doi      = {},
  url      = {https://www.academia.edu/download/108004706/jav.pdf}
}


@article{ref79,
  title    = {Identification, Analysis and Characterization of Base Units of Bird Vocal Communication: The White Spectacled Bulbul (Pycnonotus xanthopygos) as a Case …},
  author   = {A Marck, Y Vortman, O Kolodny, ...},
  year     = {2022},
  journal  = {Frontiers in Behavioral …},
  abstract = {… Given the large amount of acoustic data accumulated from automated recorders, for which … an automatic detection and analysis system based on audio signal processing algorithms and …},
  keywords = {},
  doi      = {10.3389/fnbeh.2021.812939},
  url      = {https://www.frontiersin.org/articles/10.3389/fnbeh.2021.812939/full}
}


@article{ref80,
  title    = {Deep neural networks for automated detection of marine mammal species},
  author   = {Y Shiu, KJ Palmer, MA Roch, E Fleishman, X Liu, ...},
  year     = {2020},
  journal  = {Scientific reports},
  abstract = {… The deep nets that we considered may be applicable to ongoing passive acoustic monitoring efforts. For example, the Autobuoy call detection system 67 in Massachusetts Bay is …},
  keywords = {},
  doi      = {},
  url      = {https://www.nature.com/articles/s41598-020-57549-y}
}


@book{ref81,
  title    = {Deep Learning Applied to Animal Linguistics},
  author   = {C Bergler},
  year     = {2023},
  journal  = {},
  abstract = {… foundation, further extended by additional acoustic and behavioral data material, collected … species, while addressing the following essential acoustic and image-related biological re…},
  keywords = {},
  doi      = {},
  url      = {https://search.proquest.com/openview/93f10711ba6e4b4dfaa729d8cc1fe28f/1?pq-origsite=gscholar&cbl=2026366&diss=y}
}


@article{ref82,
  title    = {Improving the workflow to crack Small, Unbalanced, Noisy, but Genuine (SUNG) datasets in bioacoustics: The case of bonobo calls},
  author   = {V Arnaud, F Pellegrino, S Keenan, ...},
  year     = {2023},
  journal  = {PLoS computational …},
  abstract = {… most recent advances in machine learning applied to a SUNG … We implement acoustic parameterization in three feature … signatures cluster in the bonobo acoustic space. We then …},
  keywords = {},
  doi      = {},
  url      = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010325}
}


@article{ref83,
  title    = {Analysis of soundscapes as an ecological tool},
  author   = {RP Schoeman, C Erbe, G Pavan, ...},
  year     = {2022},
  journal  = {Exploring animal …},
  abstract = {… , and discusses how passive acoustic monitoring applies to soundscape ecology research, … The majority of aerial feeding bats, at the opposite end of the body-size scale, produce short …},
  keywords = {},
  doi      = {},
  url      = {https://library.oapen.org/bitstream/handle/20.500.12657/60833/1/978-3-030-97540-1.pdf#page=225}
}


@misc{ref84,
  title    = {Acoustic phenology of tropical resident birds differs between native forest species and parkland colonizer species},
  author   = {L Berman, W Xuan Tan, U Grafe, ...},
  year     = {2024},
  journal  = {Journal of Avian …},
  abstract = {… Long-term acoustic monitoring in combination with machine learning … tailor-made species-specific machine learning classifiers to determine the … Automatic detection and results …},
  keywords = {},
  doi      = {10.1111/jav.03298},
  url      = {https://nsojournals.onlinelibrary.wiley.com/doi/abs/10.1111/jav.03298}
}


@misc{ref85,
  title    = {Benchmarking automated detection and classification approaches for monitoring of endangered species: a case study on gibbons from Cambodia},
  author   = {DJ Clink, H Cross-Jaya, J Kim, AH Ahmad, M Hong, ...},
  year     = {2024},
  journal  = {bioRxiv},
  abstract = {… 1.1 Passive acoustic monitoring 41 The use of passive acoustic monitoring (PAM), a technique that utilizes autonomous 42 acoustic recording units (ARUs) , has seen a steady increase …},
  keywords = {},
  doi      = {10.1101/2024.08.17.608420.abstract},
  url      = {https://www.biorxiv.org/content/10.1101/2024.08.17.608420.abstract}
}


@misc{ref86,
  title    = {Multi-year soundscape recordings and automated call detection reveals varied impact of moonlight on calling activity of neotropical forest katydids},
  author   = {LB Symes, S Madhusudhana, ...},
  year     = {2024},
  journal  = {… of the Royal …},
  abstract = {… , katydid bycatch in mist nets (set for bats), and total sound levels in ambient forest … acoustic monitoring studies have attempted to resolve individual species or genera within the acoustic …},
  keywords = {},
  doi      = {10.1098/rstb.2023.0110},
  url      = {https://royalsocietypublishing.org/doi/abs/10.1098/rstb.2023.0110}
}


@article{ref87,
  title    = {A system for monitoring acoustics to supplement an animal welfare plan for bottlenose dolphins},
  author   = {BL Jones, M Oswald, S Tufano, M Baird, ...},
  year     = {2021},
  journal  = {Journal of Zoological …},
  abstract = {… and analyze marine mammal acoustic data, and is designed to provide a flexible, module-based and user-friendly platform to assist in passive acoustic monitoring of marine mammals. …},
  keywords = {},
  doi      = {},
  url      = {https://www.mdpi.com/2673-5636/2/2/15}
}


@article{ref88,
  title    = {Use of acoustic monitoring to estimate occupancy of the Antioquia Brushfinch (Atlapetes blancae), a critically endangered species, in San Pedro de los …},
  author   = {M Díaz-Vallejo, S Chaparro-Herrera, ...},
  year     = {2023},
  journal  = {Journal of Field …},
  abstract = {… In the present work, we sampled 80 sites (30 m radius circles) to monitor acoustic activity using … The probability of obtaining acoustic records of this species with the set of autonomous …},
  keywords = {},
  doi      = {},
  url      = {https://journal.afonet.org/vol94/iss2/art4/}
}


@misc{ref89,
  title    = {Biodiversity assessment in temperate biomes using ecoacoustics},
  author   = {A Farina, N Pieretti},
  year     = {2017},
  journal  = {Ecoacoustics: The Ecological Role of …},
  abstract = {… Passive acoustic monitoring is powered by a new generation of digital recorders able to capture the sounds of nature at different sampling frequencies and at different times of day. …},
  keywords = {},
  doi      = {10.1002/9781119230724.ch7},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119230724.ch7}
}


@article{ref90,
  title    = {Multi-level LSTM framework with hybrid sonic features for human–animal conflict evasion},
  author   = {R Varun Prakash, V Karthikeyan, S Vishali, ...},
  year     = {2024},
  journal  = {The Visual Computer},
  abstract = {… The bottleneck of delay transmission in passive acoustic monitoring is addressed in [14] and [15]. In [14] the problem of delay transmission is overcome by end-to-end differentiable …},
  keywords = {},
  doi      = {10.1007/s00371-024-03588-9},
  url      = {https://link.springer.com/article/10.1007/s00371-024-03588-9}
}


@misc{ref91,
  title    = {Rthoptera: Standardised Insect Bioacoustics in R},
  author   = {F Rivas, C Brizio, FM Buzzetti, B Pijanowski},
  year     = {2024},
  journal  = {bioRxiv},
  abstract = {… Although acoustic monitoring has improved greatly in the last decades, 280 automatic detection for insect species is lagged due to lack of baseline data. As a contribution to this effort, …},
  keywords = {},
  doi      = {10.1101/2024.11.04.621915.abstract},
  url      = {https://www.biorxiv.org/content/10.1101/2024.11.04.621915.abstract}
}


@article{ref92,
  title    = {Assessing the viability of density estimation for cetaceans from passive acoustic fixed sensors throughout the life cycle of an Offshore E&P Field Development},
  author   = {CG Booth, CS Oedekoven, D Gillespie, ...},
  year     = {2017},
  journal  = {SMRU …},
  abstract = {… uses fixed passive acoustic monitoring (PAM) to determine animal density based on methods developed by the Density Estimation for Cetaceans from passive Acoustic Fixed sensors (…},
  keywords = {},
  doi      = {},
  url      = {https://gisserver.intertek.com/JIP/DMS/ProjectReports/Cat4/Other/Booth2017_CetaceansandPAM.pdf}
}


@misc{ref93,
  title    = {Computational bioacoustic scene analysis},
  author   = {D Stowell},
  year     = {2018},
  journal  = {Computational analysis of sound scenes and events},
  abstract = {… Passive acoustic monitoring … The most robust approaches to acoustic estimates of location make use of multiple simultaneous recordings, from microphones arranged in a fixed array of …},
  keywords = {},
  doi      = {10.1007/978-3-319-63450-0_11},
  url      = {https://link.springer.com/chapter/10.1007/978-3-319-63450-0_11}
}


@article{ref94,
  title    = {Sensing ecosystem dynamics via audio source separation: A case study of marine soundscapes off northeastern Taiwan},
  author   = {TH Lin, T Akamatsu, Y Tsao},
  year     = {2021},
  journal  = {PLoS Computational Biology},
  abstract = {… the acoustic behaviors of marine animals. This study applied machine learning techniques to … The model can automatically learn acoustic features and effectively separate sounds of …},
  keywords = {},
  doi      = {},
  url      = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008698}
}


@misc{ref95,
  title    = {Bioacoustic monitoring to determine addiction levels of primates to the human sphere: A feasibility study on Japanese macaques},
  author   = {H Enari, HS Enari},
  year     = {2023},
  journal  = {American Journal of Primatology},
  abstract = {… To facilitate the automatic detection and classification of targeted calls, various advanced statistical procedures based on machine learning or deep learning techniques are now …},
  keywords = {},
  doi      = {10.1002/ajp.23558},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ajp.23558}
}


@misc{ref96,
  title    = {Progress and outlook for soundscape ecology},
  author   = {Y Zhao, X Shen, S Li, Y Zhang, R Peng, ...},
  year     = {2020},
  journal  = {Biodiversity …},
  abstract = {… methodology used, and acoustic indices developed from these … : (1) acoustic composition of soundscape; (2) acoustic … (4) the development of acoustic indices for biodiversity monitoring. …},
  keywords = {},
  doi      = {10.17520/biods.2020114},
  url      = {https://www.biodiversity-science.net/EN/10.17520/biods.2020114}
}


@article{ref97,
  title    = {Assessing the drivers of soundscape structure along a gradient of disturbance in southeast Cameroon},
  author   = {J Diepstraten},
  year     = {2020},
  journal  = {},
  abstract = {… This study uses passive acoustic monitoring, a relatively new method… is the automatic detection and classification of sounds in an … Since bats, which produce ultrasonic sounds, were not …},
  keywords = {},
  doi      = {},
  url      = {http://kronendak.nl/wp-content/uploads/2021/02/Assessing-the-drivers-of-soundscape-structure-along-a-gradient-of-disturbance-in-southeast-Cameroon_Johan-Diepstraten_Final-version.pdf}
}


@misc{ref98,
  title    = {Acoustic Response and Detection of Marine Mammals Using an Advanced Digital Acoustic Recording Tag (Rev 3)},
  author   = {PL Tyack, ...},
  year     = {2007},
  journal  = {},
  abstract = {… that may be detected using passive acoustic monitoring. NUWC had already demonstrated … for passive acoustic monitoring for beaked whales. The passive acoustic monitoring of …},
  keywords = {},
  doi      = {},
  url      = {https://apps.dtic.mil/sti/citations/ADA606315}
}


@misc{ref99,
  title    = {Variações espaciais e temporais dos botos-da-tainha via monitoramento contínuo do comportamento acústico},
  author   = {B Romeu},
  year     = {2022},
  journal  = {},
  abstract = {… Studying cetaceans through acoustic behavior allows that continuous monitoring because … In this way, I have implemented passive acoustic monitoring (PAM) to investigate the Tursiops …},
  keywords = {},
  doi      = {},
  url      = {https://repositorio.ufsc.br/handle/123456789/247333}
}


@misc{ref100,
  title    = {Sound patterns of snapping shrimp, fish, and dolphins in an estuarine soundscape of the southeastern USA},
  author   = {A Monczak, C Mueller, ME Miller, Y Ji, ...},
  year     = {2019},
  journal  = {Marine Ecology …},
  abstract = {… We performed passive acoustic monitoring at 6 locations (ie 4M, 9M, 14M, 19M, 34M, and … these results with snap counts obtained from automatic detection. Pearson’s correlation was …},
  keywords = {},
  doi      = {},
  url      = {https://www.int-res.com/abstracts/meps/v609/p49-68/}
}


@book{ref101,
  title    = {Where the Wild Things Are: Computer Vision for Global-Scale Biodiversity Monitoring},
  author   = {SM Beery},
  year     = {2023},
  journal  = {},
  abstract = {… a: The BirdNET algorithm [79] was used to detect Carolina wren vocalizations in more than 35000 hours of passive acoustic monitoring data from Ithaca, New York, allowing researchers …},
  keywords = {},
  doi      = {},
  url      = {https://search.proquest.com/openview/7b36cb2f9f8b5cfc91bbb586d7859489/1?pq-origsite=gscholar&cbl=18750&diss=y}
}


@misc{ref102,
  title    = {Emerging technologies in citizen science and potential for insect monitoring},
  author   = {JK Sheard, T Adriaens, DE Bowler, ...},
  year     = {2024},
  journal  = {… of the Royal …},
  abstract = {… Although acoustic monitoring is not yet routinely deployed for insects, bush crickets have been monitored as part of a citizen science bat monitoring scheme in France since 2006, which …},
  keywords = {},
  doi      = {10.1098/rstb.2023.0106},
  url      = {https://royalsocietypublishing.org/doi/abs/10.1098/rstb.2023.0106}
}


@article{ref103,
  title    = {A fish and dolphin biophony in the boat noise-dominated soundscape of the Cres-Lošinj archipelago (Croatia)},
  author   = {M Picciulin, M Bolgan, N Rako-Gospić, ...},
  year     = {2022},
  journal  = {journal of Marine …},
  abstract = {… acoustics sensors (PAM: passive acoustic monitoring), are now … If automatic detection tools are better developed for marine … sound type diversity makes automatic detection not feasible. …},
  keywords = {},
  doi      = {},
  url      = {https://www.mdpi.com/2077-1312/10/2/300}
}


@article{ref104,
  title    = {An image processing based paradigm for the extraction of tonal sounds in cetacean communications},
  author   = {A Kershenbaum, MA Roch},
  year     = {2013},
  journal  = {The Journal of the Acoustical Society of …},
  abstract = {… In contrast, when the goal is the characterization of acoustic and other properties of the calls… Many cetacean species produce stereotyped vocalizations with certain acoustic elements …},
  keywords = {},
  doi      = {},
  url      = {https://pubs.aip.org/asa/jasa/article/134/6/4435/945460}
}


@misc{ref105,
  title    = {Biosonar behaviour of free-ranging porpoises},
  author   = {T Akamatsu, D Wang, K Wang, ...},
  year     = {2005},
  journal  = {Proceedings of the …},
  abstract = {… of aquatic animals, we developed a miniature stereo acoustic data logger and used it on eight … Here, we examine the acoustic activity and behaviour of free-ranging echolocating finless …},
  keywords = {},
  doi      = {10.1098/rspb.2004.3024},
  url      = {https://royalsocietypublishing.org/doi/abs/10.1098/rspb.2004.3024}
}


@article{ref106,
  title    = {Monitoring Northern Bobwhite (Colinus virginianus) occupancy on the landscape-scale in southern Iowa, USA},
  author   = {RO Wilson},
  year     = {2024},
  journal  = {},
  abstract = {… An emerging potential solution is passive acoustic monitoring with Autonomous Recording Units (ARU) which can be deployed across a large area during the covey calling period and …},
  keywords = {},
  doi      = {},
  url      = {https://search.proquest.com/openview/d86635f38f1f1016b16612a33c99ada5/1?pq-origsite=gscholar&cbl=18750&diss=y}
}


@misc{ref107,
  title    = {2020 State of the Science Report, Chapter 10: Environmental Monitoring Technologies and Techniques for Detecting Interactions of Marine Animals with Turbines},
  author   = {DJ Hasselman, DR Barclay, R Cavagnaro, C Chandler, ...},
  year     = {2020},
  journal  = {},
  abstract = {… Within the context of monitoring MRE devices, passive acoustic monitoring (PAM) … Despite a growing body of PAM effort around MRE devices, no commercially available acoustic …},
  keywords = {},
  doi      = {},
  url      = {https://www.osti.gov/biblio/1633202}
}


@article{ref108,
  title    = {Prince Rupert–Aurora LNG Acoustic Monitoring Study},
  author   = {H Frouin-Mouy, H Yurk, X Mouy, B Martin},
  year     = {2016},
  journal  = {},
  abstract = {… Passive acoustic monitoring using multiple recorders is a reliable … Acoustic detection and subsequent classification of marine mammal calls require that animals produce acoustic …},
  keywords = {},
  doi      = {},
  url      = {https://projects.eao.gov.bc.ca/api/document/58923173b637cc02bea163f0/fetch/Appendix_O_Acoustic_Monitoring_Final_screening.pdf}
}


@article{ref109,
  title    = {Temporal patterns in the soundscape of the port area in an urban estuary},
  author   = {AM Milanelli, MR Rossi-Santos, PF Fruet, ...},
  year     = {2024},
  journal  = {Estuarine, Coastal and …},
  abstract = {… The use of passive acoustic monitoring (PAM) can help in the detection of preferred areas and periods for fish reproduction and, consequently, serve as a tool for conservation of the …},
  keywords = {},
  doi      = {},
  url      = {https://www.sciencedirect.com/science/article/pii/S0272771423003864}
}


@book{ref110,
  title    = {Gene-culture coevolution in a social cetacean: integrating acoustic and genetic data to understand population structure in the short-finned pilot whale …},
  author   = {A Van Cise},
  year     = {2017},
  journal  = {},
  abstract = {… For example, a study of acoustic and genetic structure in the Okinawa least horseshoe bat revealed strong female philopatry and vertical transmission of echolocation frequencies, and …},
  keywords = {},
  doi      = {},
  url      = {https://search.proquest.com/openview/a60a0eba504bcfd699f7e892e864e8b4/1?pq-origsite=gscholar&cbl=18750}
}


@misc{ref111,
  title    = {Characteristics of fin whale vocalizations recorded on instruments in the northeast Pacific Ocean},
  author   = {MMJ Weirathmueller},
  year     = {2016},
  journal  = {},
  abstract = {… One of the drawbacks of using acoustic monitoring to study … the use of passive acoustic monitoring to better understand … were detected using an automatic detection algorithm based on …},
  keywords = {},
  doi      = {},
  url      = {https://digital.lib.washington.edu/researchworks/handle/1773/38189}
}


@article{ref112,
  title    = {Assessment of the effects of the offshore wind farm Egmond aan Zee (OWEZ) for harbour porpoise (comparison T0 and T1)},
  author   = {M Scheidat, GM Aarts, AG Bakker, S Brasseur, ...},
  year     = {2012},
  journal  = {},
  abstract = {… acoustic monitoring of echolocation sounds at eight stations equipped with stationary acoustic … kHz, which makes the signals ideal for automatic detection. Most other sounds in the sea, …},
  keywords = {},
  doi      = {},
  url      = {http://www.informatiehuismarien.nl/publish/pages/113881/owez_r_253_t1_20120202_harbour_porpoises_4219.pdf}
}


@article{ref113,
  title    = {Biotremology as a new tool of ecoacoustics},
  author   = {I Akassou, M Ciolli, V Mazzoni},
  year     = {2021},
  journal  = {JOURNAL OF …},
  abstract = {… Passive Acoustic Monitoring reveals the co-occurring presence of two threatened sympatric … O35- Songs of a fishing bat: echolocation call variation of the greater bulldog bat across the …},
  keywords = {},
  doi      = {},
  url      = {https://openpub.fmach.it/bitstream/10449/69182/1/JME_vol_19_2021_special_issue_3.pdf}
}


@misc{ref114,
  title    = {Wildlife monitoring and research using camera-trapping technology across China: The current status and future issues},
  author   = {Z Xiao, W Xiao, T Wang, S Li, X Lian, ...},
  year     = {2022},
  journal  = {Biodiversity …},
  abstract = {Abstract: Background: Innovation in the application of intelligent sensors, artificial intelligence, and information technology has greatly increased the potential for global biodiversity …},
  keywords = {},
  doi      = {10.17520/biods.2022451},
  url      = {https://www.biodiversity-science.net/EN/10.17520/biods.2022451}
}


@article{ref115,
  title    = {Environmental Effects of Offshore Wind Development},
  author   = {AE Copping, TJ Carlson, S Matzner, LA Hanna, ...},
  year     = {2012},
  journal  = {},
  abstract = {… such as birds and bats by using thermal imagery; and … However, the manual methods that are required to process the … of using both MMO and passive acoustic monitoring (PAM) to …},
  keywords = {},
  doi      = {},
  url      = {https://www.academia.edu/download/43295189/Environmental_Effects_of_Offshore_Wind_D20160302-105396-1gen07u.pdf}
}


@misc{ref116,
  title    = {soundClass: An automatic sound classification tool for biodiversity monitoring using machine learning},
  author   = {B Silva, F Mestre, S Barreiro, PJ Alves, JM Herrera},
  year     = {2022},
  journal  = {Silva},
  abstract = {… Passive acoustic monitoring, a non- invasive technique, is increasingly used to study animal … We illustrate the package functionality on bat echolocation calls, bird songs and whale …},
  keywords = {},
  doi      = {},
  url      = {https://dspace.uevora.pt/rdpc/handle/10174/33324}
}


@misc{ref117,
  title    = {Monitoramento acústico passivo: detecção de cetáceos odontocetos no litoral norte do Estado de São Paulo},
  author   = {DD Barcellos},
  year     = {2019},
  journal  = {},
  abstract = {… acoustic monitoring (PAM) to assess ecological aspects. The aim of this study was to develop a passive acoustic monitoring … , it was made acoustic recordings with visual confirmation of …},
  keywords = {},
  doi      = {},
  url      = {https://www.teses.usp.br/teses/disponiveis/21/21134/tde-13032020-151153/en.php}
}


@article{ref118,
  title    = {Open-source workflow approaches to passive acoustic monitoring of bats},
  author   = {Brinklov, SMM; Macaulay, J; Bergler, C; Tougaard, J; Beedholm, K; Elmeros, M; Madsen, PT},
  year     = {2023},
  journal  = {METHODS IN ECOLOGY AND EVOLUTION},
  abstract = {1. The affordability, storage and power capacity of compact modern recording hardware have evolved passive acoustic monitoring (PAM) of animals and soundscapes into a non-invasive, cost-effective tool for research and ecological management particularly useful for bats and toothed whales that orient and forage using ultrasonic echolocation. The use of PAM at large scales hinges on effective automated detectors and species classifiers which, combined with distance sampling approaches, have enabled species abundance estimation of toothed whales. But standardized, user-friendly and open access automated detection and classification workflows are in demand for this key conservation metric to be realized for bats. 2. We used the PAMGuard toolbox including its new deep learning classification module to test the performance of four open-source workflows for automated analyses of acoustic datasets from bats. Each workflow used a different initial detection algorithm followed by the same deep learning classification algorithm and was evaluated against the performance of an expert manual analyst. 3. Workflow performance depended strongly on the signal-to-noise ratio and detection algorithm used: the full deep learning workflow had the best classification accuracy (<= 67%) but was computationally too slow for practical large-scale bat PAM. Workflows using PAMGuard's detection module or triggers onboard an SM4BAT or AudioMoth accurately classified up to 47%, 59% and 34%, respectively, of calls to species. Not all workflows included noise sampling critical to estimating changes in detection probability over time, a vital parameter for abundance estimation. The workflow using PAMGuard's detection module was 40 times faster than the full deep learning workflow and missed as few calls (recall for both similar to 0.6), thus balancing computational speed and performance. 4. We show that complete acoustic detection and classification workflows for bat PAM data can be efficiently automated using open-source software such as PAMGuard and exemplify how detection choices, whether pre-or post-deployment, hardware or software-driven, affect the performance of deep learning classification and the downstream ecological information that can be extracted from acoustic recordings. In particular, understanding and quantifying detection/classification accuracy and the probability of detection are key to avoid introducing biases that may ultimately affect the quality of data for ecological management.},
  keywords = {automated; bat; classification; deep learning; detection; echolocation; open source; passive acoustic monitoring},
  doi      = {10.1111/2041-210X.14131},
  url      = {0}
}


@article{ref119,
  title    = {PNW-Cnet v4: Automated species identification for passive acoustic monitoring},
  author   = {Ruff, ZJ; Lesmeister, DB; Jenkins, JMA; Sullivan, CM},
  year     = {2023},
  journal  = {SOFTWAREX},
  abstract = {We present PNW-Cnet v4, a deep neural net with an associated Shiny-based application designed to facilitate efficient data processing to detect terrestrial wildlife species through passive acoustic monitoring. PNW-Cnet v4 is a deep convolutional neural network that detects audio signatures of 37 focal species of birds and mammals that inhabit forests of the Pacific Northwest, USA, along with other commonly occurring forest sounds. The primary objective of developing PNW-Cnet v4 was to support a long-term northern spotted owl (Strix occidentalis caurina) monitoring program. By incorporating additional species classes, PNW-Cnet v4 expands applicability of the program to broadscale biodiversity research and monitoring. Using the Shiny app with PNW-Cnet v4, users can process audio data using a graphical user interface, summarize apparent detections visually, and export results in tabular format. & COPY; 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).},
  keywords = {Bioacoustics; Machine learning; Automated detection; Wildlife monitoring; Ecology; Biodiversity},
  doi      = {10.1016/j.softx.2023.101473},
  url      = {0}
}


@article{ref120,
  title    = {Deep learning in marine bioacoustics: a benchmark for baleen whale detection},
  author   = {Schall, E; Kaya, II; Debusschere, E; Devos, P; Parcerisas, C},
  year     = {2024},
  journal  = {REMOTE SENSING IN ECOLOGY AND CONSERVATION},
  abstract = {Passive acoustic monitoring (PAM) is commonly used to obtain year-round continuous data on marine soundscapes harboring valuable information on species distributions or ecosystem dynamics. This continuously increasing amount of data requires highly efficient automated analysis techniques in order to exploit the full potential of the available data. Here, we propose a benchmark, which consists of a public dataset, a well-defined task and evaluation procedure to develop and test automated analysis techniques. This benchmark focuses on the special case of detecting animal vocalizations in a real-world dataset from the marine realm. We believe that such a benchmark is necessary to monitor the progress in the development of new detection algorithms in the field of marine bioacoustics. We ultimately use the proposed benchmark to test three detection approaches, namely ANIMAL-SPOT, Koogu and a simple custom sequential convolutional neural network (CNN), and report performances. We report the performance of the three detection approaches in a blocked cross-validation fashion with 11 site-year blocks for a multi-species detection scenario in a large marine passive acoustic dataset. Performance was measured with three simple metrics (i.e., true classification rate, noise misclassification rate and call misclassification rate) and one combined fitness metric, which allocates more weight to the minimization of false positives created by noise. Overall, ANIMAL-SPOT performed the best with an average fitness metric of 0.6, followed by the custom CNN with an average fitness metric of 0.57 and finally Koogu with an average fitness metric of 0.42. The presented benchmark is an important step to advance in the automatic processing of the continuously growing amount of PAM data that are collected throughout the world's oceans. To ultimately achieve usability of developed algorithms, the focus of future work should be laid on the reduction of the false positives created by noise. We present a benchmark for detecting animal vocalizations in marine passive acoustic data including a published dataset, a concrete task and metrics to report. Three deep learning models for bioacoustics are tested on this benchmark and their performances are reported. Future efforts in the field should aim at the reduction of false-positive rates in order to assure usability of the automated techniques. image},
  keywords = {Baleen whales; big data; deep learning; marine bioacoustics; passive acoustic monitoring (PAM); sound detection},
  doi      = {10.1002/rse2.392},
  url      = {0}
}


@article{ref121,
  title    = {Unsupervised acoustic classification of individual gibbon females and the implications for passive acoustic monitoring},
  author   = {Clink, DJ; Klinck, H},
  year     = {2021},
  journal  = {METHODS IN ECOLOGY AND EVOLUTION},
  abstract = {Passive acoustic monitoring (PAM) has the potential to greatly improve our ability to monitor cryptic yet vocal animals. Advances in automated signal detection have increased the scope of PAM, but distinguishing between individuals-which is necessary for density estimation-remains a major challenge. When individual identity is known, supervised classification techniques can be used to distinguish between individuals. Supervised methods require labelled training data, whereas unsupervised techniques do not. If the acoustic signals of individuals are sufficiently different, the number of clusters might represent the number of individuals sampled. The majority of applications of unsupervised techniques in animal vocalizations have focused on quantifying species-specific call repertoires. However, with increased interest in PAM applications, unsupervised methods that can distinguish between individuals are needed. Here we use an existing dataset of Bornean gibbon female calls with known identity from five sites on Malaysian Borneo to test the ability of three different unsupervised clustering algorithms (affinity propagation, K-medoids and Gaussian mixture model-based clustering) to distinguish between individuals. Calls from different gibbon females are readily distinguishable using supervised techniques. For internal validation of unsupervised cluster solutions, we calculated silhouette coefficients. For external validation, we compared clustering results with female identity labels using a standard metric: normalized mutual information. We also calculated classification accuracy by assigning unsupervised cluster solutions to females based on which cluster had the highest number of calls from a particular female. We found that affinity propagation clustering consistently outperformed the other algorithms for all metrics used. In particular, classification accuracy of affinity propagation clustering was more consistent as the number of females increased, and when we randomly sampled females across sites. We conclude that unsupervised techniques may be useful for providing additional information regarding individual identity for PAM applications. We stress that although we use gibbons as a case study, these methods will be applicable for any individually distinct vocal animal.},
  keywords = {affinity propagation; Gaussian mixture models; Hylobates; K‐ medoids; normalized mutual information; passive acoustic monitoring; unsupervised clustering},
  doi      = {10.1111/2041-210X.13520},
  url      = {0}
}


@article{ref122,
  title    = {Classification of animal sounds in a hyperdiverse rainforest using convolutional neural networks with data augmentation},
  author   = {Sun, YR; Maeda, TM; Solís-Lemus, C; Pimentel-Alarcón, D; Burivalová, Z},
  year     = {2022},
  journal  = {ECOLOGICAL INDICATORS},
  abstract = {To protect tropical forest biodiversity, we need to be able to detect it reliably, cheaply, and at scale. Automated detection of sound producing animals from passively recorded soundscapes via machine-learning approaches is a promising technique towards this goal, but it is constrained by the necessity of large training data sets. Using soundscapes from a tropical forest in Borneo and a Convolutional Neural Network model (CNN), we investigate i) the minimum viable training data set size for accurate prediction of call types ('sonotypes'), and ii) the extent to which data augmentation and transfer learning can overcome the issue of small and imbalanced training data sets. We found that even relatively high sample sizes (>80 per sonotype) lead to mediocre accuracy, which however improved significantly with data augmentation and transfer learning, including at extremely small sample sizes (3 per sonotype), regardless of taxonomic group or call characteristics. Neither transfer learning nor data augmentation alone achieved high accuracy. Our results suggest that transfer learning and data augmen-tation could make the use of CNNs to classify species' vocalizations feasible even for small soundscape-based projects with many rare species. Retraining our open-source model requires only basic programming skills which makes it possible for individual conservation initiatives to match their local context, in order to enable more evidence-informed management of biodiversity.},
  keywords = {Bioacoustics; Convolutional neural network; Conservation; Data augmentation; Passive 30 acoustic monitoring; Sound classification; Tropical forest; Transfer learning},
  doi      = {10.1016/j.ecolind.2022.109621},
  url      = {0}
}


@inproceedings{ref123,
  title    = {Automated Detection and Identification of Blue and Fin Whale Foraging Calls by Combining Pattern Recognition and Machine Learning Techniques},
  author   = {Huang, HC; Huang, MJ; Joseph, J; Margolina, T},
  year     = {2016},
  journal  = {OCEANS 2016 MTS/IEEE MONTEREY},
  abstract = {a novel approach has been developed for detecting and classifying foraging calls of two mysticete species in passive acoustic recordings. This automated detector/classifier applies a computer-vision based technique, a pattern recognition method, to detect the foraging calls and remove ambient noise effects. The detected calls were then classified as blue whale D-calls [1] or fin whale 40-Hz calls [2] using a logistic regression classifier, a machine learning technique. The detector/classifier has been trained using the 2015 Detection, Classification, Localization and Density Estimation (DCLDE 2015, Scripps Institution of Oceanography UCSD [3]) low-frequency annotated set of passive acoustic data, collected in the Southern California Bight, and its out-of-sample performance was estimated by using a crossvalidation technique. The DCLDE 2015 scoring tool was used to estimate the detector/classifier performance in a standardized way. The pattern recognition algorithm's out-of-sample performance was scored as 96.68% recall with 92.03 % precision. The machine learning algorithm's out-of-sample prediction accuracy was 95.20%. The result indicated the potential of this detector/classifier on real-time passive acoustic marine mammal monitoring and bioacoustics signal processing.},
  keywords = {whale; pattern recognition; machine learning; foraging call},
  doi      = {10.1109/OCEANS.2016.7761269},
  url      = {0}
}


@article{ref124,
  title    = {CDPNet: conformer-based dual path joint modeling network for bird sound recognition},
  author   = {Guo, HM; Jian, HF; Wang, YY; Wang, HC; Cheng, QH; Zheng, SK; Li, YH},
  year     = {2024},
  journal  = {APPLIED INTELLIGENCE},
  abstract = {Bird species monitoring is important for the preservation of biological diversity because it provides fundamental information for biodiversity assessment and protection. Automatic acoustic recognition is considered to be an essential technology for realizing automatic monitoring of bird species. Current deep learning-based bird sound recognition methods do not fully conduct long-term correlation modeling along both the time and frequency axes of the spectrogram. Additionally, these methods have not completely studied the impact of different scales of features on the final recognition. To solve the abovementioned problems, we propose a Conformer-based dual path joint modeling network (CDPNet) for bird sound recognition. To the best of our knowledge, this is the first attempt to adopt Conformer in the bird sound recognition task. Specifically, the proposed CDPNet mainly consists of a dual-path time-frequency joint modeling module (DPTFM) and a multi-scale feature fusion module (MSFFM). The former aims to simultaneously capture time-frequency local features, long-term time dependence, and long-term frequency dependence to better model bird sound characteristics effectively. The latter is designed to improve recognition accuracy by fusing different scales of features. The proposed algorithm is implemented on an edge computing platform, NVIDIA Jetson Nano, to build a real-time bird sound recognition monitoring system. The ablation experimental results verify the benefit of using the DPTFM and the MSFFM. Through training and testing on the Semibirdaudio dataset containing 27,155 sound clips and the public Birdsdata dataset, the proposed CDPNet outperforms the other state-of-the-art models in terms of F1-score, precision, recall, and accuracy.},
  keywords = {Bird sound recognition; Long-term time dependence; Long-term frequency dependence; Multi-scale feature fusion; Monitoring system},
  doi      = {10.1007/s10489-024-05362-9},
  url      = {0}
}


@article{ref125,
  title    = {TreeVibes: Modern Tools for Global Monitoring of Trees for Borers},
  author   = {Rigakis, I; Potamitis, I; Tatlas, NA; Potirakis, SM; Ntalampiras, S},
  year     = {2021},
  journal  = {SMART CITIES},
  abstract = {Simple Summary We demonstrate that remote, automatic monitoring of probed trees for borers at global scales is currently technologically feasible. Vibroacoustic recorders, one per tree, sample on a prescheduled basis (e.g., 20 s per hour) short clips of the internal vibroacoustic soundscene of trees. These clips are compressed and wirelessly transmitted on cloud services where deep learning networks screen those data and tag if a tree is infested or not. This approach allows us to integrate information over a large time span (from a single day to weeks) before reaching a decision on the infestation state of the tree. We aim at automatizing inspection services against wood-boring insects in commodity entry point, forests and tree cultivations and directing only ambiguous cases to a human observer. Abstract Is there a wood-feeding insect inside a tree or wooden structure? We investigate several ways of how deep learning approaches can massively scan recordings of vibrations stemming from probed trees to infer their infestation state with wood-boring insects that feed and move inside wood. The recordings come from remotely controlled devices that sample the internal soundscape of trees on a 24/7 basis and wirelessly transmit brief recordings of the registered vibrations to a cloud server. We discuss the different sources of vibrations that can be picked up from trees in urban environments and how deep learning methods can focus on those originating from borers. Our goal is to match the problem of the accelerated-due to global trade and climate change- establishment of invasive xylophagus insects by increasing the capacity of inspection agencies. We aim at introducing permanent, cost-effective, automatic monitoring of trees based on deep learning techniques, in commodity entry points as well as in wild, urban and cultivated areas in order to effect large-scale, sustainable pest-risk analysis and management of wood boring insects such as those from the Cerambycidae family (longhorn beetles).},
  keywords = {Cerambycidae; longhorn beetles; vibroacoustic monitoring; pest monitoring; pest detection},
  doi      = {10.3390/smartcities4010017},
  url      = {0}
}
